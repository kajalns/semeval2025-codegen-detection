{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOxvl5gy2wMaDRKKq69Mbte"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"w7PGv62ztPuZ"},"outputs":[],"source":["#Kagggle installation and Semeval dataset download setup\n","!pip -q install kaggle\n","\n","import os\n","import shutil\n","from google.colab import files\n","\n","os.makedirs(\"/root/.kaggle\", exist_ok=True)\n","print(\"Upload kaggle.json\")\n","uploaded = files.upload()\n","\n","fname = next(iter(uploaded.keys()))\n","shutil.move(fname, \"/root/.kaggle/kaggle.json\")\n","os.chmod(\"/root/.kaggle/kaggle.json\", 0o600)\n","\n","!kaggle --version\n","!kaggle datasets list -s \"semeval task 13\" | head -n 10\n","\n","SLUG = \"daniilor/semeval-2026-task13\"\n","TARGET = \"/content/semeval_task13\"\n","!mkdir -p \"$TARGET\"\n","!kaggle datasets download -d \"$SLUG\" -p \"$TARGET\"\n","!unzip -o \"$TARGET\"/*.zip -d \"$TARGET\"\n"]},{"cell_type":"code","source":["#set up paths for both subtask A and subtask B\n","from pathlib import Path\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","ROOT = Path(TARGET)\n","\n","#handle extra folder layer if present\n","if (ROOT / \"SemEval-2026-Task13\").exists():\n","    BASE_DIR = ROOT / \"SemEval-2026-Task13\"\n","else:\n","    BASE_DIR = ROOT\n","\n","TASK_A_DIR = BASE_DIR / \"task_a\"\n","TASK_B_DIR = BASE_DIR / \"task_b\"\n","\n","print(\"BASE_DIR:\", BASE_DIR)\n","print(\"TASK_A_DIR:\", TASK_A_DIR)\n","print(\"TASK_B_DIR:\", TASK_B_DIR)\n","\n","print(\"\\nFiles in task_a:\")\n","for p in TASK_A_DIR.iterdir():\n","    print(\" -\", p.name)\n","\n","print(\"\\nFiles in task_b:\")\n","for p in TASK_B_DIR.iterdir():\n","    print(\" -\", p.name)\n"],"metadata":{"id":"Xn_fbszatriX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#load train / validation / test for both tasks\n","\n","train_a = pd.read_parquet(TASK_A_DIR / \"task_a_training_set_1.parquet\")\n","val_a  = pd.read_parquet(TASK_A_DIR / \"task_a_validation_set.parquet\")\n","test_a  = pd.read_parquet(TASK_A_DIR / \"task_a_test_set_sample.parquet\")\n","train_b =pd.read_parquet(TASK_B_DIR/\"task_b_training_set.parquet\")\n","val_b  = pd.read_parquet(TASK_B_DIR / \"task_b_validation_set.parquet\")\n","test_b  = pd.read_parquet(TASK_B_DIR / \"task_b_test_set_sample.parquet\")\n","\n","print(\"Task A shapes:\")\n","print(\"Train:\", train_a.shape)\n","print(\"Val  :\", val_a.shape)\n","print(\"Test :\", test_a.shape)\n","\n","print(\"\\nTask B shapes:\")\n","print(\"Train:\", train_b.shape)\n","print(\"Val  :\", val_b.shape)\n","print(\"Test :\", test_b.shape)\n"],"metadata":{"id":"yGlH97FWtrsy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#data exploration function\n","\n","def explore_dataset(df, name: str):\n","    \"\"\"\n","    Print basic information about a dataset.\n","    \"\"\"\n","    print(\"\\n\" + \"=\" * 30)\n","    print(f\"{name.upper()} set analysis\")\n","    print(\"=\" * 30)\n","\n","    print(f\"shape: {df.shape}\")\n","    print(f\"columns: {list(df.columns)}\")\n","\n","    print(\"\\nmissing values:\")\n","    print(df.isnull().sum())\n","\n","    print(\"\\ndata types:\")\n","    print(df.dtypes)\n","\n","    if \"label\" in df.columns:\n","        print(\"\\nlabel distribution:\")\n","        label_counts = df[\"label\"].value_counts().sort_index()\n","        for label, count in label_counts.items():\n","            percentage = (count / len(df)) * 100\n","            print(f\"  {label}: {count:>6} samples ({percentage:5.1f}%)\")\n","\n","    return df\n","\n","\n","def analyze_column(df, column_name: str, dataset_name: str):\n","    \"\"\"\n","    Print value counts for a given column, with percentages.\n","    \"\"\"\n","    if column_name not in df.columns:\n","        return\n","\n","    print(f\"\\n{column_name.upper()} - {dataset_name}:\")\n","    print(f\"unique values: {df[column_name].nunique()}\")\n","\n","    value_counts = df[column_name].value_counts()\n","    if df[column_name].nunique() <= 10:\n","        for value, count in value_counts.items():\n","            percentage = (count / len(df)) * 100\n","            print(f\"    {value}: {count:>6} ({percentage:5.1f}%)\")\n","    else:\n","        print(\"top 5 values:\")\n","        top_5 = value_counts.head(5)\n","        for value, count in top_5.items():\n","            percentage = (count / len(df)) * 100\n","            print(f\"      {value}: {count:>6} ({percentage:5.1f}%)\")\n","\n","\n","def add_code_stats(df):\n","    \"\"\"\n","    Add code_length and line_count columns to a DataFrame.\n","    \"\"\"\n","    df = df.copy()\n","    df[\"code_length\"] = df[\"code\"].str.len()\n","    df[\"line_count\"] = df[\"code\"].str.count(\"\\n\") + 1\n","    return df\n","\n","\n","def analyze_code_content(df, name: str):\n","    \"\"\"\n","    Print summary statistics for code_length and line_count.\n","    \"\"\"\n","    print(f\"\\n{name}:\")\n","    df = add_code_stats(df)\n","\n","    print(\"code length (characters):\")\n","    print(f\"Min   : {df['code_length'].min():.0f}\")\n","    print(f\"Max   : {df['code_length'].max():.0f}\")\n","    print(f\"Mean  : {df['code_length'].mean():.1f}\")\n","    print(f\"Median: {df['code_length'].median():.1f}\")\n","\n","    print(\"line count:\")\n","    print(f\"Min   : {df['line_count'].min():.0f}\")\n","    print(f\"Max   : {df['line_count'].max():.0f}\")\n","    print(f\"Mean  : {df['line_count'].mean():.1f}\")\n","    print(f\"Median: {df['line_count'].median():.1f}\")\n","\n","    return df\n","\n","\n","def compare_human_machine(df, name: str):\n","    \"\"\"\n","    For Task A (binary labels 0/1): compare human vs machine subsets.\n","    \"\"\"\n","    df = add_code_stats(df)\n","\n","    human_df = df[df[\"label\"] == 0]\n","    machine_df = df[df[\"label\"] == 1]\n","\n","    print(f\"\\n{name}:\")\n","    print(f\"human samples   : {len(human_df):,}\")\n","    print(f\"machine samples : {len(machine_df):,}\")\n","\n","    print(\"\\ncode length comparison:\")\n","    print(f\"human   - mean: {human_df['code_length'].mean():.1f}, \"\n","          f\"median: {human_df['code_length'].median():.1f}\")\n","    print(f\"machine - mean: {machine_df['code_length'].mean():.1f}, \"\n","          f\"median: {machine_df['code_length'].median():.1f}\")\n","\n","    print(\"\\nline count comparison:\")\n","    print(f\"human   -mean: {human_df['line_count'].mean():.1f}, \"\n","          f\"median: {human_df['line_count'].median():.1f}\")\n","    print(f\"machine - mean: {machine_df['line_count'].mean():.1f}, \"\n","          f\"median: {machine_df['line_count'].median():.1f}\")\n","\n","    if \"language\" in df.columns:\n","        print(\"\\nlanguage distribution by label:\")\n","        human_lang = human_df[\"language\"].value_counts()\n","        machine_lang = machine_df[\"language\"].value_counts()\n","\n","        for lang in df[\"language\"].unique():\n","            human_count = human_lang.get(lang, 0)\n","            machine_count = machine_lang.get(lang, 0)\n","            print(f\"{lang}: human={human_count}, machine={machine_count}\")\n","\n","\n","def analyze_generators_task_b(df, name: str):\n","    \"\"\"\n","    For Task B: print generator and label distributions.\n","    \"\"\"\n","    print(f\"\\n{name}: generator and label distribution\")\n","\n","    if \"generator\" in df.columns:\n","        gen_counts = df[\"generator\"].value_counts()\n","        print(\"\\ngenerator value counts:\")\n","        for g, c in gen_counts.items():\n","            pct = c / len(df) * 100\n","            print(f\"  {g}: {c:>6} ({pct:5.1f}%)\")\n","\n","    if \"label\" in df.columns:\n","        label_counts = df[\"label\"].value_counts().sort_index()\n","        print(\"\\nlabel ID value counts:\")\n","        for lbl, c in label_counts.items():\n","            pct = c / len(df) * 100\n","            print(f\"  {lbl}: {c:>6} ({pct:5.1f}%)\")\n"],"metadata":{"id":"Cbz3gTZrtr4O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#exploration and plots of taskA\n","\n","print(\"TASK A: BASIC OVERVIEW\")\n","train_a = explore_dataset(train_a, \"Task A - Training\")\n","val_a   = explore_dataset(val_a,   \"Task A - Validation\")\n","test_a  = explore_dataset(test_a,  \"Task A - Test\")\n","\n","print(\"\\nCOLUMN ANALYSIS\")\n","for col in [\"language\", \"generator\", \"domain\"]:\n","    analyze_column(train_a, col, \"Task A - Training\")\n","    analyze_column(val_a,   col, \"Task A - Validation\")\n","    analyze_column(test_a,  col, \"Task A - Test\")\n","\n","print(\"\\nCODE CONTENT ANALYSIS\")\n","train_a = analyze_code_content(train_a, \"Task A - Training set\")\n","val_a   = analyze_code_content(val_a,   \"Task A - Validation set\")\n","test_a  = analyze_code_content(test_a,  \"Task A - Test set\")\n","\n","print(\"\\nHUMAN VS MACHINE COMPARISON \")\n","compare_human_machine(train_a, \"Task A - Training set\")\n","compare_human_machine(val_a,   \"Task A - Validation set\")\n"],"metadata":{"id":"Bbz_fCBDwLOu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#visualization of Task A\n","\n","plt.style.use(\"default\")\n","fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n","fig.suptitle(\"SemEval Task 13 - Subtask A Data Analysis\", fontsize=16, fontweight=\"bold\")\n","\n","#label distribution (Training and Validation)\n","label_data = [train_a[\"label\"].value_counts(), val_a[\"label\"].value_counts()]\n","titles = [\"Training Set\", \"Validation Set\"]\n","\n","for i, (data, title) in enumerate(zip(label_data, titles)):\n","    axes[0, i].pie(\n","        data.values,\n","        labels=[\"Human\", \"Machine\"],\n","        autopct=\"%1.1f%%\",\n","        startangle=90,\n","    )\n","    axes[0, i].set_title(f\"{title}\\nlabel Distribution\", fontweight=\"bold\")\n","\n","axes[0, 2].axis(\"off\")\n","\n","#language distribution\n","language_data_train = train_a[\"language\"].value_counts()\n","language_data_val = val_a[\"language\"].value_counts()\n","\n","axes[1, 0].bar(language_data_train.index, language_data_train.values)\n","axes[1, 0].set_title(\"Training Set - Languages\", fontweight=\"bold\")\n","axes[1, 0].set_ylabel(\"Count\")\n","axes[1, 0].tick_params(axis=\"x\", rotation=45)\n","\n","axes[1, 1].bar(language_data_val.index, language_data_val.values)\n","axes[1, 1].set_title(\"Validation Set - Languages\", fontweight=\"bold\")\n","axes[1, 1].set_ylabel(\"Count\")\n","axes[1, 1].tick_params(axis=\"x\", rotation=45)\n","\n","#code length distribution\n","axes[1, 2].hist(train_a[\"code_length\"], bins=50, alpha=0.7, label=\"Training\")\n","axes[1, 2].hist(val_a[\"code_length\"],   bins=50, alpha=0.7, label=\"Validation\")\n","axes[1, 2].set_title(\"Code Length Distribution\", fontweight=\"bold\")\n","axes[1, 2].set_xlabel(\"Code Length (characters)\")\n","axes[1, 2].set_ylabel(\"Frequency\")\n","axes[1, 2].legend()\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"pn4asNH6wLSI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#exploartion of Task B\n","\n","print(\"\\n\\nTASK B: BASIC OVERVIEW\")\n","train_b = explore_dataset(train_b, \"Task B - Training\")\n","val_b   = explore_dataset(val_b,   \"Task B - Validation\")\n","test_b  = explore_dataset(test_b,  \"Task B - Test\")\n","\n","print(\"\\nCOLUMN ANALYSIS\")\n","for col in [\"language\", \"generator\", \"domain\"]:\n","    analyze_column(train_b, col, \"Task B - Training\")\n","    analyze_column(val_b,   col, \"Task B - Validation\")\n","    analyze_column(test_b,  col, \"Task B - Test\")\n","\n","print(\"\\nCODE CONTENT ANALYSIS\")\n","train_b = analyze_code_content(train_b, \"Task B - Training set\")\n","val_b   = analyze_code_content(val_b,   \"Task B - Validation set\")\n","test_b  = analyze_code_content(test_b,  \"Task B - Test set\")\n","\n","print(\"\\nGENERATOR AND LABEL ANALYSIS\")\n","analyze_generators_task_b(train_b, \"Task B - Training set\")\n","analyze_generators_task_b(val_b,   \"Task B - Validation set\")\n"],"metadata":{"id":"ObZz97SlwLXo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#visualization of task b\n","\n","plt.style.use(\"default\")\n","fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n","fig.suptitle(\"SemEval Task 13 - Subtask B Data Analysis\", fontsize=16, fontweight=\"bold\")\n","\n","#label distribution (multi-class)\n","label_counts_b = train_b[\"label\"].value_counts().sort_index()\n","axes[0].bar(label_counts_b.index.astype(str), label_counts_b.values)\n","axes[0].set_title(\"Task B - Training label distribution\", fontweight=\"bold\")\n","axes[0].set_xlabel(\"Label ID\")\n","axes[0].set_ylabel(\"Count\")\n","axes[0].tick_params(axis=\"x\", rotation=45)\n","\n","#generator distribution\n","if \"generator\" in train_b.columns:\n","    gen_counts_b = train_b[\"generator\"].value_counts()\n","    axes[1].bar(gen_counts_b.index, gen_counts_b.values)\n","    axes[1].set_title(\"Task B - Training generators\", fontweight=\"bold\")\n","    axes[1].set_xlabel(\"Generator\")\n","    axes[1].set_ylabel(\"Count\")\n","    axes[1].tick_params(axis=\"x\", rotation=45)\n","else:\n","    axes[1].axis(\"off\")\n","\n","#code length distribution\n","axes[2].hist(train_b[\"code_length\"], bins=50)\n","axes[2].set_title(\"Task B - Code length distribution\", fontweight=\"bold\")\n","axes[2].set_xlabel(\"Code Length (characters)\")\n","axes[2].set_ylabel(\"Frequency\")\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"IhMSAEHxwXVx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Nm7kPcYSwLdO"},"execution_count":null,"outputs":[]}]}