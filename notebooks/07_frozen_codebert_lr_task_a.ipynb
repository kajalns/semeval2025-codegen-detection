{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMyDrzDn5eOTYyCQ+VVRhiu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"CnYFZAU4_e62"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from datasets import Dataset\n","from transformers import AutoTokenizer, AutoModel\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n","import os\n","\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Model\n","codebert_name = \"microsoft/codebert-base\"\n","tokenizer_cb = AutoTokenizer.from_pretrained(codebert_name)\n","model_cb = AutoModel.from_pretrained(codebert_name).to(device)\n","model_cb.eval()\n","\n","#freeze weights\n","for p in model_cb.parameters():\n","    p.requires_grad = False\n","\n","max_length = 256\n","batch_size = 16\n"]},{"cell_type":"code","source":["#Convert to HF Dataset\n","train_ds = Dataset.from_pandas(df_train[[\"code\",\"label\"]], preserve_index=False)\n","val_ds   = Dataset.from_pandas(df_val[[\"code\",\"label\"]],   preserve_index=False)\n","test_ds  = Dataset.from_pandas(df_test[[\"code\"]],          preserve_index=False)\n","\n","#Tokenize\n","def tok_fn(batch):\n","    return tokenizer_cb(\n","        batch[\"code\"],\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=max_length\n","    )\n","\n","train_tok = train_ds.map(tok_fn, batched=True, remove_columns=[\"code\"])\n","val_tok   = val_ds.map(tok_fn,   batched=True, remove_columns=[\"code\"])\n","test_tok  = test_ds.map(tok_fn,  batched=True, remove_columns=[\"code\"])\n","\n","train_tok = train_tok.rename_column(\"label\", \"labels\")\n","val_tok   = val_tok.rename_column(\"label\", \"labels\")\n","\n","train_tok.set_format(\"torch\")\n","val_tok.set_format(\"torch\")\n","test_tok.set_format(\"torch\")\n","\n","print(train_tok, val_tok, test_tok)\n"],"metadata":{"id":"Zb5EYOXH_fzj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","from tqdm.auto import tqdm\n","\n","def extract_features(hf_dataset):\n","    loader = DataLoader(hf_dataset, batch_size=batch_size, shuffle=False)\n","\n","    feats, labels = [], []\n","    with torch.inference_mode():\n","        for batch in tqdm(loader, desc=\"Extracting CodeBERT features\"):\n","            input_ids = batch[\"input_ids\"].to(device)\n","            attn_mask = batch[\"attention_mask\"].to(device)\n","\n","            out = model_cb(input_ids=input_ids, attention_mask=attn_mask)\n","            cls_vec = out.last_hidden_state[:,0,:]\n","\n","            feats.append(cls_vec.cpu().numpy())\n","            if \"labels\" in batch:\n","                labels.append(batch[\"labels\"].cpu().numpy())\n","\n","    feats = np.concatenate(feats, axis=0)\n","    if labels:\n","        labels = np.concatenate(labels, axis=0)\n","        return feats, labels\n","    return feats\n","\n","X_train, y_train = extract_features(train_tok)\n","X_val, y_val     = extract_features(val_tok)\n","X_test           = extract_features(test_tok)\n","\n","print(X_train.shape, X_val.shape, X_test.shape)\n"],"metadata":{"id":"JZ3cbxDG_izf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","import pandas as pd\n","import os\n","\n","# 1) Train Logistic Regression\n","print(\"Training Logistic Regression on CodeBERT features...\")\n","lr_model = LogisticRegression(max_iter=1000, C=1.0, solver='liblinear')\n","lr_model.fit(X_train, y_train)\n","\n","#Predict on Test data\n","print(\"Predicting...\")\n","lr_test_preds = lr_model.predict(X_test)\n","\n","# Create submission_df\n","sample_file = \"sample_submission_a.csv\"\n","submission_df = pd.read_csv(sample_file)\n","submission_df[\"label\"] = lr_test_preds\n","\n","# 4) Save\n","SAVE_DIR = \"/content/drive/MyDrive/semeval_outputs/codebert_lr_256\"\n","os.makedirs(SAVE_DIR, exist_ok=True)\n","\n","sub_path = f\"{SAVE_DIR}/submission_codebert_lr.csv\"\n","submission_df.to_csv(sub_path, index=False)\n","print(\"Saved:\", sub_path)"],"metadata":{"id":"bAgBuPWr_nxu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n","import numpy as np\n","import pandas as pd\n","import os\n","\n","\n","lr = LogisticRegression(\n","    max_iter=2000,\n","    class_weight=\"balanced\",\n","    n_jobs=-1\n",")\n","lr.fit(X_train, y_train)\n","print(\"Logistic Regression trained\")\n","\n","\n","val_probs = lr.predict_proba(X_val)           # [N_val, 2]\n","val_preds = np.argmax(val_probs, axis=-1)\n","\n","val_acc = accuracy_score(y_val, val_preds)\n","val_f1  = f1_score(y_val, val_preds, average=\"macro\")\n","\n","print(\"\\nCodeBERT Frozen + LR Validation Accuracy:\", round(val_acc, 4))\n","print(\"\\nCodeBERT Frozen + LR Validation Macro F1 :\", round(val_f1, 4))\n","\n","print(\"\\nConfusion Matrix:\")\n","print(confusion_matrix(y_val, val_preds))\n","\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_val, val_preds, digits=4))\n","\n","\n","test_probs = lr.predict_proba(X_test)         # [N_test, 2]\n","test_preds = np.argmax(test_probs, axis=-1).astype(int)\n","\n","print(\"\\nTest probs shape:\", test_probs.shape)\n","print(\"First 10 test preds:\", test_preds[:10])\n","\n","\n","SAVE_DIR = \"/content/drive/MyDrive/semeval_outputs/codebert_lr_256\"\n","os.makedirs(SAVE_DIR, exist_ok=True)\n","sample_sub = pd.read_csv(\"sample_submission_a.csv\")\n","sample_sub[\"label\"] = test_preds\n","\n","sub_path = f\"{SAVE_DIR}/subtask_a_codebert_lr_256.csv\"\n","sample_sub.to_csv(sub_path, index=False)\n","\n","print(\"\\nSubmission CSV saved to Drive:\")\n","print(sub_path)\n","sample_sub.head()\n"],"metadata":{"id":"CeWneLLQ_qge"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lUQ2Jz-b_rRJ"},"execution_count":null,"outputs":[]}]}