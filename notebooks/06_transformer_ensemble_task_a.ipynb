{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMRbPnglOFXLTwf1a2UWWMR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#load the validation dataset and testing dataset same as other transformer models.\n","#then upload the npy files from each model saved in the drive.\n","#this is an ensemble of three transformer model"],"metadata":{"id":"NRKcB3EOFa0V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n","\n","#load npy files from Codebert, Graphcodebert, and Unixoder\n","val_probs_codebert       = np.load(\"val_probs_codebert.npy\")\n","val_probs_graphcodebert  = np.load(\"val_probs_graphcodebert.npy\")\n","val_probs_unixcoder      = np.load(\"val_probs_unixcoder.npy\")\n","\n","test_probs_codebert      = np.load(\"test_probs_codebert.npy\")\n","test_probs_graphcodebert = np.load(\"test_probs_graphcodebert.npy\")\n","test_probs_unixcoder     = np.load(\"test_probs_unixcoder.npy\")\n","\n","print(\"val_probs_codebert shape      :\", val_probs_codebert.shape)\n","print(\"val_probs_graphcodebert shape :\", val_probs_graphcodebert.shape)\n","print(\"val_probs_unixcoder shape     :\", val_probs_unixcoder.shape)\n","\n","print(\"test_probs_codebert shape      :\", test_probs_codebert.shape)\n","print(\"test_probs_graphcodebert shape :\", test_probs_graphcodebert.shape)\n","print(\"test_probs_unixcoder shape     :\", test_probs_unixcoder.shape)\n","\n","# validation label\n","y_val = df_val[\"label\"].astype(int).values\n","print(\"y_val shape:\", y_val.shape)\n","\n","assert val_probs_codebert.shape[0] == len(y_val)\n","assert val_probs_graphcodebert.shape[0] == len(y_val)\n","assert val_probs_unixcoder.shape[0] == len(y_val)\n","\n","#grid search for best weights\n","best_f1 = -1.0\n","best_w  = None\n","best_val_probs_ens = None\n","\n","#step size for weights(0.1 is usually enough)\n","grid = np.linspace(0, 1, 11)\n","\n","for w1 in grid:  #CodeBERT\n","    for w2 in grid:  #GraphCodeBERT\n","        if w1 + w2 > 1.0:\n","            continue\n","        w3 = 1.0 - (w1 + w2)  #UniXcoder\n","\n","        #ensemble probabilities on validation\n","        val_probs_ens = (\n","            w1 * val_probs_codebert +\n","            w2 * val_probs_graphcodebert +\n","            w3 * val_probs_unixcoder\n","        )\n","\n","        val_preds_ens = val_probs_ens.argmax(axis=-1)\n","        f1 = f1_score(y_val, val_preds_ens, average=\"macro\")\n","\n","        if f1 > best_f1:\n","            best_f1 = f1\n","            best_w  = (w1, w2, w3)\n","            best_val_probs_ens = val_probs_ens\n","\n","print(\"\\nbest ensemble weights(CodeBERT, GraphCodeBERT, UniXcoder):\", best_w)\n","print(f\"best validation macro F1: {best_f1:.4f}\")\n","\n","#detailed metrics for best ensemble on validation set\n","val_preds_best = best_val_probs_ens.argmax(axis=-1)\n","val_acc_best   = accuracy_score(y_val, val_preds_best)\n","\n","print(f\"\\nensemble Validation Accuracy : {val_acc_best:.4f}\")\n","print(f\"ensemble Validation Macro F1 : {best_f1:.4f}\")\n","\n","cm = confusion_matrix(y_val, val_preds_best)\n","print(\"\\nensemble confusion matrix (rows=true, cols=pred):\")\n","print(cm)\n","\n","print(\"\\nEnsemble Classification Report:\")\n","print(classification_report(y_val, val_preds_best, digits=4))\n","\n","\n","np.save(\"val_probs_ensemble.npy\", best_val_probs_ens)\n","print(\"\\nSaved: val_probs_ensemble.npy\")\n","\n","#best weights to TEST probs\n","w1, w2, w3 = best_w\n","\n","test_probs_ensemble = (\n","    w1 * test_probs_codebert +\n","    w2 * test_probs_graphcodebert +\n","    w3 * test_probs_unixcoder\n",")\n","\n","test_preds_ensemble = test_probs_ensemble.argmax(axis=-1).astype(int)\n","\n","print(\"\\nEnsemble Test predictions shape:\", test_preds_ensemble.shape)\n","print(\"First 10 ensemble test preds:\", test_preds_ensemble[:10])\n","\n","# Save ensemble test probabilities\n","np.save(\"test_probs_ensemble.npy\", test_probs_ensemble)\n","print(\"Saved: test_probs_ensemble.npy\")\n","\n","#ensemble submission csv\n","sample_filename = \"sample_submission_a.csv\"\n","sample_sub_ens  = pd.read_csv(sample_filename)\n","\n","print(\"\\nSample submission shape:\", sample_sub_ens.shape)\n","print(\"Number of ensemble test predictions:\", len(test_preds_ensemble))\n","\n","if len(sample_sub_ens) != len(test_preds_ensemble):\n","    print(\"Length mismatch: sample_sub rows:\", len(sample_sub_ens), \"| test_preds:\", len(test_preds_ensemble))\n","else:\n","    # label column name\n","    if \"label\" in sample_sub_ens.columns:\n","        label_col = \"label\"\n","    else:\n","        label_col = sample_sub_ens.columns[1]\n","\n","    sample_sub_ens[label_col] = test_preds_ensemble\n","\n","    sub_path_ens = \"subtask_a_ensemble.csv\"\n","    sample_sub_ens.to_csv(sub_path_ens, index=False)\n","    print(f\"\\nsaved ensemble submission file: {sub_path_ens}\")\n","    print(sample_sub_ens.head())\n"],"metadata":{"id":"YGVFK9ExEzir"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uw4ygWZsEzmD"},"execution_count":null,"outputs":[]}]}