{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNo1v+PtaanR33xhX7NqyMm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"r6cIjiK5_KO6"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","\n","from sklearn.metrics import accuracy_score, f1_score, classification_report\n","from google.colab import files\n","\n","\n","\n","#validation and test data -- downloaded dataset from semeval task 2026 task 13\n","val_path  = \"validation.parquet\"\n","test_path = \"test.parquet\"\n","\n","df_val  = pd.read_parquet(val_path)\n","df_test = pd.read_parquet(test_path)\n","\n","print(\"Val shape :\", df_val.shape)\n","print(\"Test shape:\", df_test.shape)\n","print(\"Val columns:\", df_val.columns.tolist())\n","\n","#truth labels\n","y_true = df_val[\"label\"].astype(int).values\n","\n","#probabilities from npy files\n","codebert_dev  = np.load(\"codebert_dev_probs_en.npy\")\n","codebert_test = np.load(\"codebert_test_probs_en.npy\")\n","\n","graph_dev  = np.load(\"Graphcodebert_dev_probs_en.npy\")\n","graph_test = np.load(\"Graphcodebert_test_probs_en.npy\")\n","\n","unix_dev  = np.load(\"unixcoder_dev_probs_weighted.npy\")\n","unix_test = np.load(\"unixcoder_test_probs_weighted.npy\")\n","\n","print(\"Shapes:\")\n","print(\"CodeBERT   validation:\", codebert_dev.shape,   \"test:\", codebert_test.shape)\n","print(\"GraphCodeB validation:\", graph_dev.shape,      \"test:\", graph_test.shape)\n","print(\"UniXcoder  validation:\", unix_dev.shape,       \"test:\", unix_test.shape)\n","\n","assert codebert_dev.shape[0] == len(df_val)\n","assert graph_dev.shape[0]    == len(df_val)\n","assert unix_dev.shape[0]     == len(df_val)\n","\n","\n","MODEL_KEYS      = [\"codebert\", \"graphcodebert\", \"unixcoder\"]\n","dev_probs_list  = [codebert_dev, graph_dev, unix_dev]\n","test_probs_list = [codebert_test, graph_test, unix_test]\n","\n","\n","\n","print(\"\\neach model evaluation metrics\")\n","model_f1s = []\n","\n","for key, dev_p in zip(MODEL_KEYS, dev_probs_list):\n","    preds = dev_p.argmax(axis=1)\n","    acc   = accuracy_score(y_true, preds)\n","    f1    = f1_score(y_true, preds, average=\"macro\")\n","    model_f1s.append(f1)\n","    print(f\"{key:12s} â€” Accuracy: {acc:.4f} | Macro-F1: {f1:.6f}\")\n","\n","#weighted ensemble\n","weights = np.array(model_f1s, dtype=\"float64\")\n","weights = weights / weights.sum()\n","\n","print(\"\\nEnsemble weights by validation macro-F1):\")\n","for k, w in zip(MODEL_KEYS, weights):\n","    print(f\"  {k:12s}: {w:.4f}\")\n","\n","#stack: num_models, num_dev, num_classes\n","dev_stack = np.stack(dev_probs_list, axis=0)\n","\n","#weighted average probs over models\n","dev_ens_probs = np.tensordot(weights, dev_stack, axes=(0, 0))\n","dev_ens_preds = dev_ens_probs.argmax(axis=1)\n","\n","ens_acc = accuracy_score(y_true, dev_ens_preds)\n","ens_f1  = f1_score(y_true, dev_ens_preds, average=\"macro\")\n","\n","print(\"\\nWeighted Ensemble (CodeBERT + GraphCodeBERT + UniXcoder)\")\n","print(f\"validation Accuracy: {ens_acc:.6f}\")\n","print(f\"validation Macro-F1: {ens_f1:.6f}\")\n","\n","print(\"\\nClassification report (ensemble):\")\n","print(classification_report(y_true, dev_ens_preds, digits=3))\n","\n","\n","#ensemble test\n","test_stack     = np.stack(test_probs_list, axis=0)\n","test_ens_probs = np.tensordot(weights, test_stack, axes=(0, 0))\n","test_ens_preds = test_ens_probs.argmax(axis=1).astype(int)\n","\n","print(\"\\nTest ensemble predictions:\")\n","print(\"Num test preds:\", len(test_ens_preds))\n","print(\"First 10 labels:\", test_ens_preds[:10])\n","\n","\n","test_labels_for_sub = test_ens_preds\n","#submission csv\n","print(\"\\nUploading sample submission file\")\n","uploaded = files.upload()\n","\n","sample_filename = next(iter(uploaded.keys()))\n","print(\"Loaded file:\", sample_filename)\n","\n","sample_sub = pd.read_csv(sample_filename)\n","print(\"Sample submission shape:\", sample_sub.shape)\n","print(sample_sub.head())\n","\n","if len(sample_sub) != len(test_labels_for_sub):\n","    print(\"Length mismatch: sample_sub rows:\", len(sample_sub), \"| test_preds:\", len(test_labels_for_sub))\n","else:\n","    if \"label\" in sample_sub.columns:\n","        label_col = \"label\"\n","    else:\n","        label_col = sample_sub.columns[1]\n","\n","    sample_sub[label_col] = test_labels_for_sub\n","\n","    print(\"\\nSubmission preview (ensemble):\")\n","    print(sample_sub.head())\n","\n","    out_name = \"subtask_b_ensemble_weighted.csv\"\n","    sample_sub.to_csv(out_name, index=False)\n","    print(f\"\\nSaved ensemble submission file: {out_name}\")\n"]}]}