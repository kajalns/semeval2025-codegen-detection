{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm","authorship_tag":"ABX9TyOFfb8vivpP8fFfj/k4j780"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip -q install transformers accelerate datasets evaluate"],"metadata":{"id":"A8zrMTbAimoa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"GiAimtzNRqIK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A5rFovDKUxYB"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import torch\n","import numpy as np\n","import torch\n","from datasets import Dataset\n","from pathlib import Path\n","import joblib\n","\n","from sklearn.metrics import (\n","    accuracy_score,\n","    f1_score,\n","    confusion_matrix,\n","    classification_report,\n",")\n","\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSequenceClassification,\n","    TrainingArguments,\n","    Trainer,\n","    DataCollatorWithPadding,\n",")\n"]},{"cell_type":"code","source":["#data already downloaded using 01_data_overview_task_ab.ipynb\n","\n","ROOT = Path(\"/content/semeval_task13\")\n","\n","#handling extra folder layer if present\n","if (ROOT / \"SemEval-2026-Task13\").exists():\n","    BASE_DIR = ROOT / \"SemEval-2026-Task13\"\n","else:\n","    BASE_DIR = ROOT\n","\n","TASK_A_DIR = BASE_DIR / \"task_a\"\n","\n","print(\"BASE_DIR:\", BASE_DIR)\n","print(\"TASK_A_DIR:\", TASK_A_DIR)\n","print(\"Files in task_a:\")\n","for p in TASK_A_DIR.iterdir():\n","    print(\" -\", p.name)\n"],"metadata":{"id":"HdXvYC7eg3_-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#load subtask A data\n","\n","train_path = TASK_A_DIR / \"task_a_training_set_1.parquet\"\n","val_path   = TASK_A_DIR / \"task_a_validation_set.parquet\"\n","test_path  = TASK_A_DIR / \"task_a_test_set_sample.parquet\"\n","\n","df_train = pd.read_parquet(train_path)\n","df_val   = pd.read_parquet(val_path)\n","df_test  = pd.read_parquet(test_path)\n","\n","print(\"Train shape:\", df_train.shape)\n","print(\"Val shape  :\", df_val.shape)\n","print(\"Test shape :\", df_test.shape)\n","print(\"\\nColumns:\", df_train.columns.tolist())\n","\n","df_train.head()\n"],"metadata":{"id":"_h4zFyXPg7SK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#basic preprocessing\n","df_train = df_train[[\"code\", \"label\"]].dropna()\n","df_val   = df_val[[\"code\", \"label\"]].dropna()\n","\n","df_train[\"label\"] = df_train[\"label\"].astype(int)\n","df_val[\"label\"]   = df_val[\"label\"].astype(int)\n","\n","print(df_train.head())\n","print(df_val.head())\n","\n"],"metadata":{"id":"erRYVSTugxKe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#building HF daatset\n","train_ds_gcb = Dataset.from_pandas(df_train[[\"code\", \"label\"]], preserve_index=False)\n","val_ds_gcb   = Dataset.from_pandas(df_val[[\"code\", \"label\"]],   preserve_index=False)\n","test_ds_gcb  = Dataset.from_pandas(df_test[[\"code\"]],           preserve_index=False)\n","\n","print(train_ds_gcb)\n","print(val_ds_gcb)\n","print(test_ds_gcb)\n","\n","#GraphCodeBERT Tokenizer\n","gcb_model_name = \"microsoft/graphcodebert-base\"\n","gcb_tokenizer  = AutoTokenizer.from_pretrained(gcb_model_name)\n","\n","#ensure pad token\n","if gcb_tokenizer.pad_token is None:\n","    gcb_tokenizer.pad_token = gcb_tokenizer.eos_token or gcb_tokenizer.cls_token\n","\n","max_length = 256\n","\n","def gcb_tokenize_fn(batch):\n","    return gcb_tokenizer(\n","        batch[\"code\"],\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=max_length,\n","    )\n","\n","#map tokenizer\n","train_tok_gcb = train_ds_gcb.map(gcb_tokenize_fn, batched=True, remove_columns=[\"code\"])\n","val_tok_gcb   = val_ds_gcb.map(gcb_tokenize_fn,   batched=True, remove_columns=[\"code\"])\n","test_tok_gcb  = test_ds_gcb.map(gcb_tokenize_fn,  batched=True, remove_columns=[\"code\"])\n","\n","train_tok_gcb = train_tok_gcb.rename_column(\"label\", \"labels\")\n","val_tok_gcb   = val_tok_gcb.rename_column(\"label\", \"labels\")\n","\n","#set torch format\n","train_tok_gcb.set_format(type=\"torch\")\n","val_tok_gcb.set_format(type=\"torch\")\n","test_tok_gcb.set_format(type=\"torch\")\n"],"metadata":{"id":"fl3C20decCnZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.environ[\"WANDB_DISABLED\"] = \"true\"\n","os.environ[\"WANDB_MODE\"] = \"disabled\"\n","\n","num_labels = 2\n","gcb_model = AutoModelForSequenceClassification.from_pretrained(\n","    gcb_model_name,\n","    num_labels=num_labels,\n","    problem_type=\"single_label_classification\",\n",")\n","\n","#set pad token id\n","gcb_model.config.pad_token_id = gcb_tokenizer.pad_token_id\n","\n","metric = evaluate.load(\"f1\")\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    preds = np.argmax(logits, axis=-1)\n","    macro_f1 = metric.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n","    acc = (preds == labels).mean()\n","    return {\"macro_f1\": macro_f1, \"accuracy\": acc}\n","\n","batch_size = 16\n","\n","gcb_training_args = TrainingArguments(\n","    output_dir=\"task_a_graphcodebert\", #temporary folder\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=3,\n","    learning_rate=2e-5,\n","    weight_decay=0.01,\n","    logging_steps=200,\n","    save_steps=2000,\n","    logging_dir=\"logs_graphcodebert\",\n",")\n","\n","gcb_trainer = Trainer(\n","    model=gcb_model,\n","    args=gcb_training_args,\n","    train_dataset=train_tok_gcb,\n","    eval_dataset=val_tok_gcb,\n","    tokenizer=gcb_tokenizer,\n","    compute_metrics=compute_metrics,\n",")\n","\n","#Training\n","gcb_trainer.train()\n","\n","#evaluation on validation set\n","gcb_eval_results = gcb_trainer.evaluate(eval_dataset=val_tok_gcb)\n","print(\"GraphCodeBERT Validation results:\", gcb_eval_results)\n"],"metadata":{"id":"vUIX9yaUcLyW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#detailed results\n","gcb_val_outputs = gcb_trainer.predict(val_tok_gcb)\n","gcb_val_logits  = gcb_val_outputs.predictions             # [N_val, num_labels]\n","gcb_val_preds   = np.argmax(gcb_val_logits, axis=-1)      # predicted class ids\n","\n","y_val_true = df_val[\"label\"].astype(int).values\n","\n","gcb_val_acc = accuracy_score(y_val_true, gcb_val_preds)\n","gcb_val_f1  = f1_score(y_val_true, gcb_val_preds, average=\"macro\")\n","\n","print(f\"\\nGraphCodeBERT Validation Accuracy : {gcb_val_acc:.4f}\")\n","print(f\"GraphCodeBERT Validation Macro F1 : {gcb_val_f1:.4f}\")\n","\n","#Confusion matrix & report\n","gcb_cm = confusion_matrix(y_val_true, gcb_val_preds)\n","print(\"\\nGraphCodeBERT Confusion Matrix (rows=true, cols=pred):\")\n","print(gcb_cm)\n","\n","print(\"\\nGraphCodeBERT Classification Report:\")\n","print(classification_report(y_val_true, gcb_val_preds, digits=4))\n","\n","#probabilities (softmax over logits)\n","gcb_val_probs = torch.softmax(torch.from_numpy(gcb_val_logits), dim=-1).numpy()\n","\n","print(\"\\nGraphCodeBERT First 5 (true, pred, prob_0, prob_1):\")\n","for i in range(5):\n","    print(\n","        f\"i={i:3d} | y={y_val_true[i]} | Å·={gcb_val_preds[i]} \"\n","        f\"| p0={gcb_val_probs[i,0]:.4f} | p1={gcb_val_probs[i,1]:.4f}\"\n","    )\n","\n","\n","np.save(\"val_probs_graphcodebert.npy\", gcb_val_probs)#for ensemble\n","print(\"\\nsaved for ensemble:val_probs_graphcodebert.npy\")\n","\n","\n"],"metadata":{"id":"X3X1LvgYcXp1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test predictions for GraphCodeBERT\n","test_tok_gcb.set_format(type=\"torch\")\n","\n","gcb_test_outputs = gcb_trainer.predict(test_tok_gcb)\n","gcb_test_logits  = gcb_test_outputs.predictions\n","\n","#probabilities for each class (for ensemble)\n","gcb_test_probs = torch.softmax(torch.from_numpy(gcb_test_logits), dim=-1).numpy()\n","gcb_test_preds = np.argmax(gcb_test_logits, axis=-1).astype(int)\n","\n","print(\"GraphCodeBERT Test predictions shape:\", gcb_test_preds.shape)\n","print(\"GraphCodeBERT Test probs shape      :\", gcb_test_probs.shape)\n","print(\"First 10 GraphCodeBERT predictions :\", gcb_test_preds[:10])\n","\n","np.save(\"test_probs_graphcodebert.npy\", gcb_test_probs)\n","\n","print(\"\\nSaved for ensemble:test_probs_graphcodebert.npy\")\n","\n"],"metadata":{"id":"4-AhAuc4cCqj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#smaple submission for the competition\n","sample_filename = \"sample_submission_a.csv\"\n","print(\"Loaded file:\", sample_filename)\n","\n","sample_sub = pd.read_csv(sample_filename)\n","\n","print(\"Sample submission shape:\", sample_sub.shape)\n","print(\"First rows of sample submission:\")\n","print(sample_sub.head())\n","print(\"Number of test predictions:\", len(test_preds))\n","\n","# 3) Fill label column and save\n","if len(sample_sub) != len(test_preds):\n","    print(\"Length mismatch: sample_sub rows:\", len(sample_sub), \"| test_preds:\", len(test_preds))\n","else:\n","    if \"label\" in sample_sub.columns:\n","        label_col = \"label\"\n","    else:\n","        label_col = sample_sub.columns[1]\n","\n","    sample_sub[label_col] = test_preds\n","\n","    print(\"\\nSubmission preview:\")\n","    print(sample_sub.head())\n","\n","    sub_path = \"subtask_a_graphcodebert_final.csv\"\n","    sample_sub.to_csv(sub_path, index=False)\n","    print(f\"\\nSaved submission file: {sub_path}\")"],"metadata":{"id":"O-nIkhB9cCtT"},"execution_count":null,"outputs":[]}]}