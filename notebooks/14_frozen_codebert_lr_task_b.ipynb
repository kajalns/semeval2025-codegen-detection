{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm","authorship_tag":"ABX9TyOYaI7PY53HvxcCPUGQVwdN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7qSN5wwlLgSL"},"outputs":[],"source":["!pip -q install transformers\n","\n","from pathlib import Path\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","from torch.nn.functional import normalize\n","from transformers import AutoTokenizer, AutoModel\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, f1_score, classification_report\n","from google.colab import files\n"]},{"cell_type":"code","source":["\n","ROOT = Path(\"/content/semeval_task13\")\n","if (ROOT / \"SemEval-2026-Task13\").exists():\n","    BASE_DIR = ROOT / \"SemEval-2026-Task13\"\n","else:\n","    BASE_DIR = ROOT\n","\n","TASK_B_DIR = BASE_DIR / \"task_b\"\n","print(\"TASK_B_DIR:\", TASK_B_DIR)\n","\n","train_path = TASK_B_DIR / \"task_b_training_set.parquet\"\n","val_path   = TASK_B_DIR / \"task_b_validation_set.parquet\"\n","test_path  = \"test.parquet\"\n","\n","df_train = pd.read_parquet(train_path)\n","df_val   = pd.read_parquet(val_path)\n","df_test  = pd.read_parquet(test_path)\n","\n","print(\"Train:\", df_train.shape, \"Val:\", df_val.shape, \"Test:\", df_test.shape)\n","print(df_train.head(2))\n"],"metadata":{"id":"Tbu0dElOVqUo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MODEL_NAME = \"microsoft/codebert-base\"\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n","encoder   = AutoModel.from_pretrained(MODEL_NAME)\n","encoder.to(device)\n","encoder.eval()\n","\n","print(\"Hidden size:\", encoder.config.hidden_size)\n"],"metadata":{"id":"_I6FMBpZN5_J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def encode_texts_to_embeddings(texts, batch_size=16, max_length=256):\n","    all_embs = []\n","\n","    for i in range(0, len(texts), batch_size):\n","        batch_texts = texts[i:i+batch_size]\n","\n","        enc = tokenizer(\n","            list(batch_texts),\n","            padding=\"max_length\",\n","            truncation=True,\n","            max_length=max_length,\n","            return_tensors=\"pt\",\n","        ).to(device)\n","\n","        with torch.no_grad():\n","            outputs = encoder(**enc)  #last_hidden_state:(B, L, H)\n","            hidden = outputs.last_hidden_state          #(B, L, H)\n","            mask   = enc[\"attention_mask\"].unsqueeze(-1) #(B, L, 1)\n","\n","            #Mean pooling only over real tokens\n","            summed  = (hidden * mask).sum(dim=1)  #(B, H)\n","            counts  = mask.sum(dim=1).clamp(min=1) #(B, 1)\n","            mean_pooled = summed / counts         #(B, H)\n","\n","            embs = mean_pooled.cpu().numpy()\n","            all_embs.append(embs)\n","\n","    return np.vstack(all_embs) #(N, H)\n"],"metadata":{"id":"oVigpjEbN9Qw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_texts = df_train[\"code\"].astype(str).values\n","X_val_texts   = df_val[\"code\"].astype(str).values\n","X_test_texts  = df_test[\"code\"].astype(str).values\n","\n","y_train = df_train[\"label\"].astype(int).values\n","y_val   = df_val[\"label\"].astype(int).values\n","\n","print(\"Encoding train...\")\n","X_train = encode_texts_to_embeddings(X_train_texts, batch_size=16, max_length=256)\n","print(\"Encoding val...\")\n","X_val   = encode_texts_to_embeddings(X_val_texts,   batch_size=16, max_length=256)\n","print(\"Encoding test...\")\n","X_test  = encode_texts_to_embeddings(X_test_texts,  batch_size=16, max_length=256)\n","\n","print(\"X_train shape:\", X_train.shape)\n","print(\"X_val shape  :\", X_val.shape)\n","print(\"X_test shape :\", X_test.shape)\n"],"metadata":{"id":"enjI-jBMOAlQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lr = LogisticRegression(\n","    max_iter=1000,\n","    multi_class=\"multinomial\",\n","    n_jobs=-1,\n","    C=1.0,\n",")\n","\n","print(\"Training LR on frozen CodeBERT features\")\n","lr.fit(X_train, y_train)\n","print(\"successfully completed\")\n"],"metadata":{"id":"qwlOnaulOIf4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_preds = lr.predict(X_val)\n","\n","val_acc = accuracy_score(y_val, val_preds)\n","val_f1  = f1_score(y_val, val_preds, average=\"macro\")\n","\n","print(f\"Frozen CodeBERT+LR â€” validation Accuracy: {val_acc:.4f} | Macro-F1: {val_f1:.4f}\")\n","print(\"\\nClassification report:\\n\")\n","print(classification_report(y_val, val_preds, digits=3))\n"],"metadata":{"id":"rNhsNKEtOLU1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_preds = lr.predict(X_test).astype(int)\n","print(\"Num test preds:\", len(test_preds))\n","print(\"First 10 test labels:\", test_preds[:10])\n"],"metadata":{"id":"DpYlRdO7OOuN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_filename = \"sample_submission_b.csv\"\n","sample_sub = pd.read_csv(sample_filename)\n","print(\"Sample submission shape:\", sample_sub.shape)\n","\n","if len(sample_sub) != len(test_preds):\n","    print(\" Length mismatch:\", len(sample_sub), \"vs\", len(test_preds))\n","else:\n","    if \"label\" in sample_sub.columns:\n","        label_col = \"label\"\n","    else:\n","        label_col = sample_sub.columns[1]\n","\n","    sample_sub[label_col] = test_preds\n","    print(\"\\nSubmission preview (Frozen CodeBERT + LR):\")\n","    print(sample_sub.head())\n","\n","    out_name = \"subtask_b_frozen_codebert_lr.csv\"\n","    sample_sub.to_csv(out_name, index=False)\n","    print(f\"\\n Saved submission file: {out_name}\")\n"],"metadata":{"id":"JxtdBuysOUB7"},"execution_count":null,"outputs":[]}]}