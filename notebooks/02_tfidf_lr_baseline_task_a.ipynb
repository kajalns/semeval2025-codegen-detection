{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOXMENTzZ2BeeSy+XDSIA+H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import f1_score, accuracy_score\n","import os\n","from google.colab import files"],"metadata":{"id":"5559-ZXPrDX_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from pathlib import Path\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import f1_score, accuracy_score\n","\n","import pandas as pd\n","import numpy as np\n","import joblib\n","#data already downloaded using 01_data_overview_task_ab.ipynb\n","ROOT = Path(\"/content/semeval_task13\")\n","\n","#handling extra folder layer if present\n","if (ROOT / \"SemEval-2026-Task13\").exists():\n","    BASE_DIR = ROOT / \"SemEval-2026-Task13\"\n","else:\n","    BASE_DIR = ROOT\n","\n","TASK_A_DIR = BASE_DIR / \"task_a\"\n","\n","print(\"BASE_DIR:\", BASE_DIR)\n","print(\"TASK_A_DIR:\", TASK_A_DIR)\n","print(\"Files in task_a:\")\n","for p in TASK_A_DIR.iterdir():\n","    print(\" -\", p.name)\n"],"metadata":{"id":"M9ZVUTSD7LnR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#loading the subtask A data\n","train_path = TASK_A_DIR / \"task_a_training_set_1.parquet\"\n","val_path   = TASK_A_DIR / \"task_a_validation_set.parquet\"\n","test_path  = TASK_A_DIR / \"task_a_test_set_sample.parquet\"\n","\n","train_df = pd.read_parquet(train_path)\n","val_df   = pd.read_parquet(val_path)\n","test_df  = pd.read_parquet(test_path)\n","\n","print(\"Train shape:\", train_df.shape)\n","print(\"Val shape  :\", val_df.shape)\n","print(\"Test shape :\", test_df.shape)\n","print(\"\\nColumns:\", train_df.columns.tolist())\n","\n","train_df.head()\n"],"metadata":{"id":"8t1YTpUu7YSd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#basic preprocessing(whitespace normalization)\n","def clean_code(text):\n","    if pd.isna(text):\n","        return \"\"\n","    return ' '.join(text.split())\n","\n","train_df['code_clean'] = train_df['code'].apply(clean_code)\n","val_df['code_clean'] = val_df['code'].apply(clean_code)\n","test_df['code_clean'] = test_df['code'].apply(clean_code)\n","\n","print(\"Basic preprocessing completed\")"],"metadata":{"id":"bs25QHKArDxP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#preparation of training data\n","X_train = train_df['code_clean']\n","y_train = train_df['label']\n","\n","X_val = val_df['code_clean']\n","y_val = val_df['label']\n","\n","X_test = test_df['code_clean']\n","y_test = test_df['label'] if 'label' in test_df.columns else None\n","\n","print(f\"Training: {len(X_train)} samples\")\n","print(f\"Validation: {len(X_val)} samples\")\n","print(f\"Test: {len(X_test)} samples\")"],"metadata":{"id":"KYurjH8krD6n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#TF-IDF + LR pipeline\n","tfidf_lr_pipeline = Pipeline([\n","    ('tfidf', TfidfVectorizer(\n","        token_pattern=r'\\b\\w+\\b|\\{|\\}|\\(|\\)|;|,|=|\\+|\\-|\\*|/',\n","        max_features=20000,\n","        min_df=2,\n","        max_df=0.9,\n","        ngram_range=(1, 2)\n","    )),\n","    ('clf', LogisticRegression(\n","        random_state=42,\n","        class_weight='balanced',\n","        max_iter=1000\n","    ))\n","])\n","\n","print(\"Training TF-IDF + Logistic Regression model\")\n","tfidf_lr_pipeline.fit(X_train, y_train)\n","print(\"Model trained!\")"],"metadata":{"id":"gn46qoYqsF7_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate on validation set\n","val_predictions = tfidf_lr_pipeline.predict(X_val)\n","val_f1 = f1_score(y_val, val_predictions, average='macro')\n","val_accuracy = accuracy_score(y_val, val_predictions)\n","\n","print(f\"VALIDATION RESULTS:\")\n","print(f\"Macro F1: {val_f1:.4f}\")\n","print(f\"Accuracy: {val_accuracy:.4f}\")\n","print(f\"Predictions - Human: {(val_predictions == 0).sum()}, Machine: {(val_predictions == 1).sum()}\")"],"metadata":{"id":"2PwBZueosN6O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#submission file\n","sample_path = \"sample_submission.csv\"\n","if not os.path.exists(sample_path):\n","    print(\"Please upload sample_submission.csv\")\n","    uploaded = files.upload()\n","    if not uploaded:\n","        raise FileNotFoundError(\"sample_submission.csv not provided.\")\n","    sample_path = list(uploaded.keys())[0]\n","\n","sample_submission = pd.read_csv(sample_path)\n","print(f\"Loaded sample submission: {sample_path}\")\n","print(f\"Columns: {list(sample_submission.columns)}\")\n","print(f\"Shape: {sample_submission.shape}\")"],"metadata":{"id":"v1s9SUFwsPlv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#creatng submission file and dataframe\n","test_predictions = tfidf_lr_pipeline.predict(X_test)\n","submission_df = sample_submission.copy()\n","submission_df['label'] = test_predictions\n","submission_path = \"submission_tfidf_baseline.csv\"  #this is the sample submission file provided by Semeval 2026 task 13\n","submission_df.to_csv(submission_path, index=False)\n","\n","print(f\"Submission file created: {submission_path}\")\n","print(f\"Submission statistics:\")\n","print(f\"Total predictions: {len(submission_df)}\")\n","print(f\"Human (0): {(test_predictions == 0).sum()}\")\n","print(f\"Machine (1): {(test_predictions == 1).sum()}\")"],"metadata":{"id":"7sH7nY0jsPw3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#download the submission file\n","files.download(submission_path)\n","print(\"Submissione file downloaded:submission_tfidf_baseline.csv\")\n"],"metadata":{"id":"xrQCCRJKrEB7"},"execution_count":null,"outputs":[]}]}